# Tag 4: Deployment auf AWS EC2 + Logging

> **Wichtig:** Wir nutzen die Techstarter AWS Sandbox unter https://sandboxes.techstarter.de/ mit einem Budget-Limit von 15‚Ç¨. Alle Ressourcen sollten am Ende aufger√§umt werden!

## Lernziele

**Kernziele (Pflicht):**
* Eine EC2-Instanz in AWS erstellen und konfigurieren
* FastAPI-Anwendung auf einem Linux-Server deployen
* Systemd Service f√ºr automatisches Starten einrichten
* Nginx als Reverse Proxy konfigurieren
* API √∂ffentlich √ºber HTTP erreichbar machen

**Bonus-Ziele (Optional):**
* Log-Dateien strukturiert erstellen und verwalten
* Cronjob f√ºr automatische S3-Uploads einrichten
* HTTPS mit Let's Encrypt aktivieren
* Monitoring und Backups implementieren

---

## Theorie: Was ist AWS EC2?

### Cloud Computing - Grundlagen

**Was ist Cloud Computing?**

Statt einen physischen Server zu kaufen und in deinem B√ºro zu betreiben, mietest du Rechenleistung von einem Cloud-Anbieter wie AWS.

**Metapher: Server mieten wie eine Wohnung**
* **Fr√ºher (eigener Server):** Du kaufst ein Haus ‚Üí Hohe Anfangskosten, du k√ºmmerst dich um alles
* **Heute (Cloud):** Du mietest eine Wohnung ‚Üí Bezahlst nur was du nutzt, Wartung √ºbernimmt der Vermieter

### Was ist EC2?

**EC2 = Elastic Compute Cloud**

EC2 ist der AWS-Service f√ºr virtuelle Server (genannt "Instanzen").

**Elastic = Flexibel:**
* Starte Server in Minuten
* Skaliere hoch oder runter je nach Bedarf
* Bezahle nur f√ºr die tats√§chliche Nutzung

**Was ist eine EC2-Instanz?**
Eine EC2-Instanz ist ein virtueller Computer in der Cloud:
* Hat CPU, RAM, Festplatte (wie ein normaler Computer)
* L√§uft auf AWS-Hardware (die du nicht siehst)
* Du hast volle Admin-Rechte √ºber `sudo` (Root-Rechte bei Bedarf)
* Du kannst darauf installieren was du willst

### EC2-Instanz-Typen

AWS bietet verschiedene Instanz-Typen f√ºr verschiedene Zwecke:

**t2.micro / t3.micro (Free Tier eligible):**
* 1-2 vCPUs (virtuelle CPUs)
* 1 GB RAM
* Perfekt f√ºr kleine Projekte und Lernen
* Im Free Tier je nach Account-Typ kostenlos/rabattiert

**t3.small (kleine Produktion):**
* 2 vCPUs
* 2 GB RAM
* Ca. 15-20‚Ç¨/Monat
* Gut f√ºr kleine APIs mit moderatem Traffic

**F√ºr unser Projekt:** W√§hle eine Instanz, die in der AWS-Konsole als **"Free tier eligible"** markiert ist (meist t2.micro oder t3.micro)!

### AWS-Regionen

AWS hat Rechenzentren auf der ganzen Welt verteilt (Regionen):

* **eu-central-1** ‚Üí Frankfurt (Deutschland)
* **eu-west-1** ‚Üí Irland
* **us-east-1** ‚Üí Virginia (USA)

**Wichtig:** W√§hle eine Region in deiner N√§he f√ºr niedrige Latenz!

### Warum EC2 f√ºr unsere API?

**Vorteile:**
* Immer verf√ºgbar (24/7)
* Feste IP-Adresse
* Echte Linux-Umgebung
* Professionelles Setup
* Du lernst Production-Deployment

**Nachteile:**
* Kostet Geld (aber Free Tier f√ºr 12 Monate)
* Mehr Konfiguration als lokaler Server
* Du musst dich um Updates k√ºmmern

---

## Theorie: Deployment-Architektur

### Wie sieht unsere finale Architektur aus?

```
Internet
   ‚îÇ
   ‚Üì
[AWS Security Group]  ‚Üê Firewall
   ‚îÇ
   ‚Üì
[Nginx :80]          ‚Üê Reverse Proxy (√∂ffentlich)
   ‚îÇ
   ‚Üì
[FastAPI :8000]      ‚Üê Unsere API (intern)
   ‚îÇ
   ‚Üì
[SQLite DB]          ‚Üê Datenbank (lokal)
   ‚îÇ
   ‚Üì
[Log-Dateien]        ‚Üê Logs
   ‚îÇ
   ‚Üì (Cronjob)
[S3 Bucket]          ‚Üê Log-Archiv
```

**Erkl√§rung der Komponenten:**

**1. Security Group (AWS-Firewall):**
* Kontrolliert welche Ports von au√üen erreichbar sind
* Wir √∂ffnen nur Port 80 (HTTP) und 22 (SSH)
* Alles andere ist blockiert

**2. Nginx (Reverse Proxy):**
* Nimmt HTTP-Anfragen von au√üen entgegen (Port 80)
* Leitet sie intern an FastAPI weiter (Port 8000)
* Warum? Nginx ist robuster, kann SSL, Load Balancing, Static Files
* FastAPI l√§uft nur intern (nicht direkt erreichbar von au√üen)

**3. FastAPI (unsere Anwendung):**
* L√§uft mit Uvicorn auf Port 8000
* Nur von localhost erreichbar
* Managed von Systemd (automatischer Start bei Neustart)

**4. SQLite:**
* Lokale Datenbank-Datei
* Liegt im gleichen Verzeichnis wie die Anwendung

**5. Logs + S3:**
* Logs werden in `/var/log/notes-api/` gespeichert
* T√§glich per Cronjob zu S3 hochgeladen
* Alte Logs werden komprimiert

### Warum Nginx statt direkt FastAPI?

**Problem mit direktem FastAPI:**
```
Internet ‚Üí FastAPI :8000
```

**Nachteile:**
* Port 8000 muss √∂ffentlich sein (un√ºblich)
* Keine SSL-Unterst√ºtzung
* Keine Load Balancing-M√∂glichkeit
* Keine Static Files (CSS, JS, Bilder)
* Weniger robust bei vielen Anfragen

**L√∂sung mit Nginx:**
```
Internet ‚Üí Nginx :80 ‚Üí FastAPI :8000 (localhost)
```

**Vorteile:**
* Standard Port 80 (HTTP) / 443 (HTTPS)
* SSL/TLS-Terminierung
* Kann mehrere FastAPI-Instanzen verwalten
* Serve Static Files effizient
* Bessere Performance
* Professioneller Standard

**Metapher:** Nginx ist wie ein Empfangschef im Restaurant:
* Nimmt G√§ste (Requests) in Empfang
* Leitet sie an den richtigen Koch (FastAPI) weiter
* Der Koch muss nicht mit jedem Gast direkt sprechen

---

## Theorie: Systemd Service

### Was ist Systemd?

Systemd ist der Service-Manager in modernen Linux-Systemen (Ubuntu, Debian, CentOS, etc.).

**Was macht Systemd?**
* Startet Services beim Booten
* √úberwacht laufende Services
* Startet Services neu, wenn sie abst√ºrzen
* Verwaltet Logs

**Ohne Systemd:**
```bash
# Du musst manuell starten:
uvicorn main:app

# Server neu gestartet? API ist weg!
# SSH-Verbindung getrennt? API ist weg!
```

**Mit Systemd:**
```bash
# Service wird automatisch gestartet:
sudo systemctl start notes-api

# Bei Server-Neustart: Automatisch wieder da!
# SSH getrennt? L√§uft weiter im Hintergrund!
```

### Systemd Unit File

Ein Systemd Service wird mit einem "Unit File" definiert:

```ini
[Unit]
Description=Notes API Service
After=network.target

[Service]
User=ubuntu
WorkingDirectory=/home/ubuntu/notes-api
ExecStart=/home/ubuntu/notes-api/venv/bin/uvicorn main:app --host 127.0.0.1 --port 8000
Restart=always

[Install]
WantedBy=multi-user.target
```

**Erkl√§rung:**
* `[Unit]` ‚Üí Allgemeine Infos √ºber den Service
* `After=network.target` ‚Üí Starte erst, wenn Netzwerk verf√ºgbar ist
* `[Service]` ‚Üí Wie der Service l√§uft
* `User=ubuntu` ‚Üí Als welcher User (nicht root!)
* `WorkingDirectory` ‚Üí Wo liegt die Anwendung
* `ExecStart` ‚Üí Kommando zum Starten
* `--host 127.0.0.1` ‚Üí Nur auf localhost h√∂ren (nicht von au√üen erreichbar)
* `--port 8000` ‚Üí Interner Port f√ºr FastAPI
* `Restart=always` ‚Üí Bei Crash automatisch neu starten
* `[Install]` ‚Üí Wann beim Boot starten

---

## Theorie: SSH und Sicherheit

### Was ist SSH?

**SSH = Secure Shell**

SSH ist ein verschl√ºsseltes Protokoll, um sich sicher mit einem entfernten Server zu verbinden.

**Metapher:** SSH ist wie ein verschl√ºsselter Telefon-Tunnel zu deinem Server:
* Alles was du tippst, ist verschl√ºsselt
* Niemand kann mith√∂ren
* Du authentifizierst dich mit einem Schl√ºssel (nicht nur Passwort)

**SSH-Verbindung aufbauen:**
```bash
ssh -i mein-key.pem ubuntu@54.93.123.456
     ^              ^       ^
     |              |       ‚îî‚îÄ‚îÄ IP-Adresse der EC2-Instanz
     |              ‚îî‚îÄ‚îÄ Username (ubuntu ist Standard bei Ubuntu AMIs)
     ‚îî‚îÄ‚îÄ Private Key (wie ein digitaler Haust√ºrschl√ºssel)
```

**Wichtig zum Username:**
* Bei **Ubuntu AMIs** ist der Standard-User: `ubuntu`
* Bei Amazon Linux AMIs w√§re es: `ec2-user`
* Bei Debian AMIs: `admin`
* Wir nutzen Ubuntu ‚Üí daher: `ubuntu@...`

### SSH-Keys verstehen

**Asymmetrische Verschl√ºsselung:**

Beim Erstellen einer EC2-Instanz erzeugt AWS ein Schl√ºsselpaar:

1. **Private Key** (mein-key.pem)
   * Bleibt bei dir auf dem Laptop
   * Wie ein Haust√ºrschl√ºssel
   * NIEMALS weitergeben!
   * Permissions: 400 (nur du kannst lesen)

2. **Public Key**
   * Liegt auf der EC2-Instanz
   * Wie ein T√ºrschloss
   * Kann √∂ffentlich sein

**Wie funktioniert es?**
```
Du (mit Private Key) ‚Üí Server (mit Public Key)
                     ‚Üê "Beweise, dass du den Private Key hast!"
                     ‚Üí [Mathematischer Beweis]
                     ‚Üê "OK, du bist authentifiziert!"
```

**Wichtig:**
* Private Key muss Permissions 400 haben:
  ```bash
  chmod 400 mein-key.pem
  ```
* Ohne diesen Key kommst du nicht auf den Server!

---

## Vorbereitung: AWS-Account und Kosten

### AWS Free Tier und Sandbox-Zugang

**F√ºr diesen Kurs nutzen wir die Techstarter AWS Sandbox:**
* Zugang √ºber: https://sandboxes.techstarter.de/
* Budget-Limit: 15‚Ç¨ pro Teilnehmer
* Alle Ressourcen sollten am Ende aufger√§umt werden

**AWS Free Tier (f√ºr eigene Accounts):**

AWS bietet ein kostenloses Kontingent f√ºr neue Accounts. Die genauen Konditionen h√§ngen vom Account-Erstellungsdatum ab:

**Legacy Free Tier (Accounts vor Juli 2025):**
* 750 Stunden EC2 t2.micro/Monat (12 Monate)
* 5 GB S3 Storage
* 20.000 GET Requests (S3)

**Aktuelles Free Tier:**
* Variiert je nach AWS-Programm
* **Wichtig:** Pr√ºfe im AWS Free Tier Dashboard die aktuellen Limits
* Achte in der EC2-Konsole auf das Label **"Free tier eligible"**

**Das bedeutet f√ºr uns:**
* W√§hle immer eine Instanz mit "Free tier eligible" Label
* In der Sandbox: Achte auf das 15‚Ç¨-Budget
* Eine kleine Instanz (t2.micro/t3.micro) 24/7 laufen lassen ist normalerweise im Free Tier abgedeckt

**Nach Free Tier (oder au√üerhalb):**
* t2.micro: ~8-10‚Ç¨/Monat
* t3.micro: ~9-11‚Ç¨/Monat
* S3 Storage: ~0,023‚Ç¨/GB/Monat
* S3 Requests: Vernachl√§ssigbar f√ºr kleine Projekte

**Kostenfallen vermeiden:**
* Nur **eine** kleine Instanz (t2/t3.micro)
* Instanz **stoppen** wenn nicht gebraucht (nicht terminate!)
* S3 Buckets regelm√§√üig aufr√§umen
* In der Sandbox: Am Ende des Tages alles aufr√§umen!

### AWS-Account erstellen

Wenn du noch keinen AWS-Account hast:

1. Gehe zu https://aws.amazon.com
2. Klicke auf "Kostenloses Konto erstellen"
3. Folge den Schritten (Kreditkarte erforderlich)
4. W√§hle "Basic Support" (kostenlos)

**Sicherheitshinweis:**
* Aktiviere MFA (Multi-Factor Authentication)
* Erstelle einen IAM-User (nicht als Root arbeiten)

---

## Live-Coding Teil 1: EC2-Instanz erstellen

### Schritt 1: In die AWS Console einloggen

1. √ñffne https://console.aws.amazon.com
2. Logge dich mit deinen Zugangsdaten ein
3. W√§hle die Region **eu-central-1** (Frankfurt)
   * Oben rechts in der Navbar
   * Wichtig: Merke dir diese Region!

### Schritt 2: EC2 Dashboard √∂ffnen

1. Suche nach "EC2" in der Suchleiste
2. Klicke auf "EC2" ‚Üí Du siehst das EC2 Dashboard
3. Klicke auf **"Launch instance"** (gro√üer oranger Button)

### Schritt 3: Instanz konfigurieren

**Name und Tags:**
```
Name: notes-api-server
```

**Application and OS Images (AMI):**
* W√§hle: **Ubuntu Server 24.04 LTS**
* Architecture: **64-bit (x86)**
* Warum Ubuntu? Weit verbreitet, gut dokumentiert, stabil

**Instance Type:**
* W√§hle: **t2.micro** oder **t3.micro** (je nachdem was als "Free tier eligible" markiert ist)
* Wichtig: Achte auf das Label **"Free tier eligible"**!
* Beide Typen haben 1 GB RAM und sind f√ºr unser Projekt perfekt

**Key Pair (Login):**
* Klicke auf **"Create new key pair"**
* Key pair name: `notes-api-key`
* Key pair type: **RSA**
* Private key format: **.pem** (f√ºr Linux/Mac) oder **.ppk** (f√ºr PuTTY/Windows)
* Klicke auf **"Create key pair"**
* Die Datei wird automatisch heruntergeladen
* **WICHTIG:** Diese Datei gut aufbewahren! Du kannst sie nicht nochmal herunterladen!

**Network Settings:**
* Klicke auf **"Edit"** (rechts oben)
* **Auto-assign public IP:** Enable (wichtig!)
* **Firewall (Security Groups):**
  * W√§hle: **"Create security group"**
  * Security group name: `notes-api-sg`
  * Description: `Security group for notes API`
  
**Inbound Security Group Rules:**

Erstelle 2 Regeln:

**Regel 1: SSH**
* Type: **SSH**
* Port: **22**
* Source: **My IP** (nur deine IP kann sich verbinden)
* Description: `SSH from my IP`

**Regel 2: HTTP**
* Type: **HTTP**
* Port: **80**
* Source: **Anywhere (0.0.0.0/0)**
* Description: `HTTP access for API`

**Warum diese Regeln?**
* SSH (Port 22) ‚Üí Damit du dich verbinden kannst
* HTTP (Port 80) ‚Üí Damit die Welt deine API nutzen kann
* Port 8000? Nicht n√∂tig! FastAPI l√§uft intern, Nginx ist das Gateway

**Configure Storage:**
* 8 GB gp3 (Standard) reicht v√∂llig

### Schritt 4: Instanz starten

1. Klicke rechts auf **"Launch instance"**
2. Warte ca. 1-2 Minuten
3. Klicke auf **"View instances"**
4. Deine Instanz sollte jetzt Status **"Running"** haben

### Schritt 5: Public IP notieren

1. Klicke auf deine Instanz
2. Notiere die **Public IPv4 address**
   * Beispiel: `54.93.123.456`
   * Diese IP brauchst du zum Verbinden!

---

## Live-Coding Teil 2: SSH-Verbindung einrichten

### Schritt 1: Private Key vorbereiten

**Linux/Mac:**

```bash
# Wechsle in den Download-Ordner
cd ~/Downloads

# Verschiebe den Key in ein sicheres Verzeichnis
mkdir -p ~/.ssh
mv notes-api-key.pem ~/.ssh/

# Setze korrekte Permissions (wichtig!)
chmod 400 ~/.ssh/notes-api-key.pem

# √úberpr√ºfe die Permissions
ls -la ~/.ssh/notes-api-key.pem
# Sollte zeigen: -r-------- (nur Lesen f√ºr dich)
```

**Windows 10/11:**

Windows 10/11 hat OpenSSH meist schon vorinstalliert. Du kannst `.pem` Dateien direkt nutzen!

```powershell
# PowerShell oder CMD √∂ffnen
# Wechsle zum Download-Ordner
cd Downloads

# Key sollte bereits die richtigen Permissions haben
# Wenn nicht, kannst du sie setzen (optional):
# icacls notes-api-key.pem /inheritance:r
# icacls notes-api-key.pem /grant:r "%USERNAME%:R"

# SSH-Verbindung testen (siehe n√§chsten Schritt)
```

**Alternative f√ºr Windows: PuTTY (falls OpenSSH fehlt)**

Falls `ssh` Befehl nicht funktioniert:

1. Lade PuTTY herunter: https://www.putty.org/
2. Lade PuTTYgen herunter (kommt mit PuTTY)
3. √ñffne PuTTYgen ‚Üí Load ‚Üí W√§hle `.pem` Datei
4. Save Private Key ‚Üí Speichere als `.ppk` Datei
5. √ñffne PuTTY:
   * Host Name: `ubuntu@DEINE_PUBLIC_IP`
   * Connection ‚Üí SSH ‚Üí Auth ‚Üí Browse ‚Üí W√§hle `.ppk` Datei
   * Open

**Empfehlung:** Nutze OpenSSH wenn m√∂glich (einfacher!)

**Warum chmod 400?**
* SSH lehnt Keys ab, die von anderen gelesen werden k√∂nnen
* 400 = Nur du kannst lesen, niemand sonst
* Sicherheitsfeature

### Schritt 2: SSH-Verbindung testen

**Linux/Mac:**
```bash
# Verbinde dich mit der EC2-Instanz
ssh -i ~/.ssh/notes-api-key.pem ubuntu@DEINE_PUBLIC_IP

# Beispiel:
ssh -i ~/.ssh/notes-api-key.pem ubuntu@54.93.123.456
```

**Windows (PowerShell/CMD):**
```powershell
# Verbinde dich mit der EC2-Instanz
ssh -i C:\Users\DEINNAME\Downloads\notes-api-key.pem ubuntu@DEINE_PUBLIC_IP

# Beispiel:
ssh -i C:\Users\Max\Downloads\notes-api-key.pem ubuntu@54.93.123.456

# Hinweis: Passe den Pfad an deinen Benutzernamen und Speicherort an
```

**Was passiert beim ersten Mal?**
```
The authenticity of host '54.93.123.456' can't be established.
ECDSA key fingerprint is SHA256:abc123...
Are you sure you want to continue connecting (yes/no)?
```

* Tippe: **yes** und Enter
* Das ist normal beim ersten Verbinden
* Der Server-Fingerprint wird gespeichert

**Wenn alles funktioniert:**
```
Welcome to Ubuntu 24.04 LTS
...
ubuntu@ip-172-31-x-x:~$
```

**Du bist jetzt auf dem Server!**

### Troubleshooting SSH

**Problem: "Permission denied (publickey)"**
```bash
# √úberpr√ºfe Permissions
ls -la ~/.ssh/notes-api-key.pem

# Sollte sein: -r--------
# Falls nicht:
chmod 400 ~/.ssh/notes-api-key.pem
```

**Problem: "Connection refused"**
* Ist die Instanz "Running"?
* Ist die IP-Adresse korrekt?
* Security Group: Ist SSH (Port 22) erlaubt von deiner IP?

**Problem: "Connection timeout"**
* Ist die Security Group korrekt?
* Ist "Auto-assign public IP" aktiviert?

---

## Live-Coding Teil 3: Server vorbereiten

Jetzt bist du auf dem Server verbunden. Lass uns die Umgebung vorbereiten.

### Schritt 1: System aktualisieren

```bash
# Paketlisten aktualisieren
sudo apt update

# Installierte Pakete upgraden
sudo apt upgrade -y

# Dauer: 1-2 Minuten
```

**Was macht das?**
* `apt update` ‚Üí L√§dt Liste der verf√ºgbaren Pakete
* `apt upgrade` ‚Üí Installiert Updates f√ºr alle Pakete
* `-y` ‚Üí Beantwortet alle Fragen automatisch mit "ja"

### Schritt 2: Ben√∂tigte Software installieren

```bash
# Python 3.12 und pip
sudo apt install -y python3 python3-pip python3-venv

# Git f√ºr Code-Management
sudo apt install -y git

# Nginx als Reverse Proxy
sudo apt install -y nginx

# AWS CLI f√ºr S3-Zugriff (wird sp√§ter gebraucht)
sudo apt install -y awscli

# √úberpr√ºfe die Installationen
python3 --version    # Sollte Python 3.12.x zeigen
pip3 --version       # Sollte pip zeigen
nginx -v             # Sollte nginx Version zeigen
git --version        # Sollte git Version zeigen
aws --version        # Sollte aws-cli Version zeigen
```

### Schritt 3: Projektverzeichnis erstellen

```bash
# Erstelle Projektordner
mkdir -p ~/notes-api
cd ~/notes-api

# √úberpr√ºfe, wo du bist
pwd
# Sollte zeigen: /home/ubuntu/notes-api
```

### Schritt 4: Code auf den Server bringen

**Option A: Code manuell erstellen (einfacher f√ºr Lernen)**

```bash
# Erstelle main.py
nano main.py
```

**Kopiere den gesamten Code aus Tag 3 main.py hinein:**
* Strg+Shift+V zum Einf√ºgen
* Strg+X zum Beenden
* Y zum Speichern
* Enter

```bash
# Erstelle db.py
nano db.py
```

**Kopiere den gesamten Code aus Tag 3 db.py hinein:**
* Gleicher Prozess

**Option B: Code via Git (professioneller)**

Wenn dein Code in einem Git-Repository ist:

```bash
# Klone dein Repository
git clone https://github.com/DEIN_USERNAME/notes-api.git
cd notes-api
```

### Schritt 5: Virtual Environment erstellen

```bash
# Erstelle venv
python3 -m venv venv

# Aktiviere venv
source venv/bin/activate

# Prompt sollte jetzt (venv) zeigen
```

### Schritt 6: Dependencies installieren

```bash
# Installiere FastAPI und Uvicorn
pip install fastapi uvicorn

# √úberpr√ºfe die Installation
pip list | grep fastapi
pip list | grep uvicorn
```

### Schritt 7: API testen (lokal auf Server)

```bash
# Starte die API (Test) - nur lokal erreichbar
uvicorn main:app --host 127.0.0.1 --port 8000

# Sollte zeigen:
# INFO:     Started server process
# INFO:     Uvicorn running on http://127.0.0.1:8000
```

**In einem neuen Terminal auf deinem Laptop:**
```bash
# Teste von au√üen (ersetze IP)
curl http://DEINE_PUBLIC_IP:8000

# PROBLEM: Connection refused!
```

**Warum funktioniert es nicht?**
* Port 8000 ist nicht in der Security Group!
* FastAPI l√§uft nur auf 127.0.0.1 (localhost) - nicht von au√üen erreichbar
* Das ist genau was wir wollen - Nginx ist das Gateway!

**Zur√ºck auf dem Server:**
```bash
# Stoppe Uvicorn
Strg+C

# Test lokal auf dem Server
curl http://localhost:8000

# Sollte jetzt die API-Response zeigen!
```

---

## Live-Coding Teil 4: Systemd Service einrichten

Jetzt machen wir die API zu einem richtigen Service, der automatisch startet.

### Schritt 1: Service-Datei erstellen

```bash
# Erstelle Service-Datei
sudo nano /etc/systemd/system/notes-api.service
```

**F√ºge folgenden Inhalt ein:**

```ini
[Unit]
Description=Notes API Service
After=network.target
# Starte den Service erst, wenn das Netzwerk bereit ist

[Service]
# Als welcher User soll der Service laufen
User=ubuntu
# Arbeitsverzeichnis
WorkingDirectory=/home/ubuntu/notes-api
# Kommando zum Starten (mit venv!)
# Wichtig: --host 127.0.0.1 ‚Üí nur lokal, Nginx ist das Gateway
ExecStart=/home/ubuntu/notes-api/venv/bin/uvicorn main:app --host 127.0.0.1 --port 8000
# Bei Crash automatisch neu starten
Restart=always
# Warte 3 Sekunden vor Neustart
RestartSec=3
# Standard Output und Error in Systemd Journal
StandardOutput=journal
StandardError=journal

[Install]
# Starte beim Booten
WantedBy=multi-user.target
```

**Speichern:** Strg+X, dann Y, dann Enter

**Erkl√§rung der wichtigsten Teile:**

* `After=network.target` ‚Üí Warte auf Netzwerk
* `User=ubuntu` ‚Üí Nicht als root laufen (Sicherheit!)
* `WorkingDirectory` ‚Üí Wo liegt die Anwendung
* `ExecStart` ‚Üí Voller Pfad zum uvicorn im venv
* `Restart=always` ‚Üí Bei Crash neu starten
* `RestartSec=3` ‚Üí 3 Sekunden Pause zwischen Restarts
* `WantedBy=multi-user.target` ‚Üí Beim Boot starten

### Schritt 2: Service aktivieren und starten

```bash
# Systemd neu laden (neue Service-Datei erkennen)
sudo systemctl daemon-reload

# Service aktivieren (beim Boot starten)
sudo systemctl enable notes-api

# Service jetzt starten
sudo systemctl start notes-api

# Status √ºberpr√ºfen
sudo systemctl status notes-api
```

**Erwartete Ausgabe:**
```
‚óè notes-api.service - Notes API Service
     Loaded: loaded (/etc/systemd/system/notes-api.service; enabled)
     Active: active (running) since ...
   Main PID: 1234 (uvicorn)
```

**Wichtige Status-Werte:**
* `loaded` ‚Üí Service-Datei wurde gelesen
* `enabled` ‚Üí Startet beim Booten
* `active (running)` ‚Üí L√§uft gerade
* Gr√ºner Punkt ‚óè ‚Üí Alles gut!

### Schritt 3: Logs ansehen

```bash
# Letzte 50 Zeilen der Logs
sudo journalctl -u notes-api -n 50

# Logs live verfolgen (wie tail -f)
sudo journalctl -u notes-api -f

# Zum Beenden: Strg+C
```

### Schritt 4: Service-Befehle (wichtig!)

```bash
# Service starten
sudo systemctl start notes-api

# Service stoppen
sudo systemctl stop notes-api

# Service neu starten
sudo systemctl restart notes-api

# Status anzeigen
sudo systemctl status notes-api

# Beim Boot aktivieren
sudo systemctl enable notes-api

# Beim Boot deaktivieren
sudo systemctl disable notes-api
```

### Schritt 5: Service testen

```bash
# API lokal testen
curl http://localhost:8000

# Sollte die API-Response zeigen

# Server neu starten (Test ob Service beim Boot startet)
sudo reboot
```

**Was passiert beim reboot?**
* SSH-Verbindung wird getrennt
* Server startet neu (1-2 Minuten)
* Service sollte automatisch starten

```bash
# Warte 2 Minuten, dann neu verbinden
ssh -i ~/.ssh/notes-api-key.pem ubuntu@DEINE_PUBLIC_IP

# Status √ºberpr√ºfen
sudo systemctl status notes-api
# Sollte "active (running)" zeigen!
```

---

## Live-Coding Teil 5: Nginx als Reverse Proxy

Jetzt machen wir die API √ºber Port 80 erreichbar.

### Schritt 1: Nginx-Konfiguration erstellen

```bash
# Erstelle Konfigurationsdatei
sudo nano /etc/nginx/sites-available/notes-api
```

**F√ºge folgenden Inhalt ein:**

```nginx
# Upstream-Definition: Wo l√§uft die FastAPI?
upstream notes_api {
    server localhost:8000;
}

server {
    # Lausche auf Port 80 (HTTP)
    listen 80;
    
    # Server-Name (ersetze mit deiner IP oder Domain)
    server_name _;
    
    # Maximale Gr√∂√üe f√ºr Uploads
    client_max_body_size 10M;
    
    # Logs
    access_log /var/log/nginx/notes-api-access.log;
    error_log /var/log/nginx/notes-api-error.log;
    
    # Alle Requests an FastAPI weiterleiten
    location / {
        # Proxy-Headers setzen
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # An FastAPI weiterleiten
        proxy_pass http://notes_api;
        
        # Timeouts
        proxy_connect_timeout 300;
        proxy_send_timeout 300;
        proxy_read_timeout 300;
    }
}
```

**Speichern:** Strg+X, dann Y, dann Enter

**Erkl√§rung der Konfiguration:**

**Upstream-Block:**
```nginx
upstream notes_api {
    server localhost:8000;
}
```
* Definiert, wo die FastAPI l√§uft
* `localhost:8000` ‚Üí Intern auf dem Server
* Kann sp√§ter mehrere Server haben (Load Balancing)

**Server-Block:**
```nginx
listen 80;
server_name _;
```
* `listen 80` ‚Üí Lausche auf HTTP-Port 80
* `server_name _` ‚Üí Akzeptiere alle Hostnamen (f√ºr IP-Zugriff)
* **Wichtig:** `_` ist ein Wildcard - funktioniert f√ºr den Zugriff per IP-Adresse
* Sp√§ter kann hier eine Domain stehen: `server_name api.example.com;` (siehe HTTPS-√úbung)
* **F√ºr IP-Zugriff bleibt `server_name _;` korrekt - nicht √§ndern!**

**Proxy-Headers:**
```nginx
proxy_set_header Host $host;
proxy_set_header X-Real-IP $remote_addr;
```
* Wichtig! FastAPI muss wissen, wer der echte Client ist
* Ohne diese Headers sieht FastAPI immer nur `127.0.0.1` (localhost)
* `X-Real-IP` ‚Üí Echte IP des Clients
* `X-Forwarded-For` ‚Üí Komplette Proxy-Chain

**Logs:**
```nginx
access_log /var/log/nginx/notes-api-access.log;
error_log /var/log/nginx/notes-api-error.log;
```
* Separate Log-Dateien f√ºr unsere API
* Access Log ‚Üí Alle Requests
* Error Log ‚Üí Nur Fehler

### Schritt 2: Nginx-Konfiguration aktivieren

```bash
# Erstelle Symlink (aktiviert die Konfiguration)
# Falls Symlink schon existiert, wird er ersetzt
sudo ln -sf /etc/nginx/sites-available/notes-api /etc/nginx/sites-enabled/

# L√∂sche die Default-Konfiguration (optional, aber empfohlen)
sudo rm -f /etc/nginx/sites-enabled/default

# √úberpr√ºfe die Nginx-Konfiguration auf Fehler
sudo nginx -t

# Erwartete Ausgabe:
# nginx: configuration file /etc/nginx/nginx.conf syntax is ok
# nginx: configuration file /etc/nginx/nginx.conf test is successful
```

**Was macht `-sf` beim ln Befehl?**
* `-s` = symbolic link (Symlink erstellen)
* `-f` = force (√ºberschreibe falls existiert - verhindert Fehler bei Wiederholung)

**Was macht `-f` beim rm Befehl?**
* `-f` = force (kein Fehler falls Datei nicht existiert)

**Was bedeutet der Symlink?**
* `sites-available/` ‚Üí Alle verf√ºgbaren Konfigurationen
* `sites-enabled/` ‚Üí Nur aktive Konfigurationen
* Nginx l√§dt nur Dateien aus `sites-enabled/`
* Symlink = Verkn√ºpfung (wie ein Shortcut)

### Schritt 3: Nginx neu starten

```bash
# Nginx neu laden (ohne Downtime)
sudo systemctl reload nginx

# Oder: Nginx neu starten
sudo systemctl restart nginx

# Status √ºberpr√ºfen
sudo systemctl status nginx
```

**Expected Output:**
```
‚óè nginx.service - A high performance web server
     Active: active (running)
```

### Schritt 4: Von au√üen testen

**Auf deinem Laptop (nicht auf dem Server):**

```bash
# HTTP-Request von deinem Laptop
curl http://DEINE_PUBLIC_IP

# Sollte jetzt die API-Response zeigen!

# Oder im Browser:
# http://DEINE_PUBLIC_IP
```

**Im Browser √∂ffnen:**
```
http://DEINE_PUBLIC_IP
http://DEINE_PUBLIC_IP/docs    ‚Üê Swagger UI
http://DEINE_PUBLIC_IP/notes
```

**üéâ Gl√ºckwunsch! Deine API ist jetzt √∂ffentlich erreichbar!**

### Schritt 5: Nginx-Logs ansehen

```bash
# Access Log (alle Requests)
sudo tail -f /var/log/nginx/notes-api-access.log

# Error Log (nur Fehler)
sudo tail -f /var/log/nginx/notes-api-error.log

# Zum Beenden: Strg+C
```

---

## Bonus: Logging und S3-Upload

Jetzt implementieren wir professionelles Logging mit automatischem Upload zu S3.

### Theorie: Warum Logs wichtig sind

**Was sind Logs?**
* Aufzeichnungen von Ereignissen in der Anwendung
* Requests, Fehler, Warnungen, Informationen
* Unverzichtbar f√ºr Debugging und Monitoring

**Problem ohne strukturiertes Logging:**
* `print()` Statements verschwinden
* Keine Historie
* Schwer nachzuvollziehen, was passiert ist

**L√∂sung: Strukturiertes Logging**
* Logs in Dateien schreiben
* Rotation (alte Logs archivieren)
* Zentrales Backup (S3)

### Schritt 1: S3-Bucket erstellen

**In der AWS Console:**

1. Suche nach "S3" in der Suchleiste
2. Klicke auf **"Create bucket"**
3. **Bucket name:** `notes-api-logs-DEINE-INITIALEN-ZAHL`
   * Beispiel: `notes-api-logs-js-2025`
   * Muss global eindeutig sein!
4. **Region:** eu-central-1 (Frankfurt)
5. **Block all public access:** AKTIVIERT (wichtig!)
6. Klicke auf **"Create bucket"**

### Schritt 2: IAM-Rolle f√ºr EC2 erstellen

Die EC2-Instanz braucht Berechtigungen, um zu S3 zu schreiben.

**In der AWS Console:**

1. Gehe zu **IAM** (Identity and Access Management)
2. Links: **Roles** ‚Üí **Create role**
3. **Trusted entity type:** AWS service
4. **Use case:** EC2 ‚Üí **Next**
5. **Permissions policies:** Suche nach `AmazonS3FullAccess`
   * F√ºr Production: Erstelle eine eingeschr√§nktere Policy!
   * F√ºr Lernen: FullAccess ist ok
6. **Next**
7. **Role name:** `EC2-S3-Access-Role`
8. **Create role**

**Rolle an EC2-Instanz anh√§ngen:**

1. Gehe zu **EC2** ‚Üí **Instances**
2. W√§hle deine Instanz
3. **Actions** ‚Üí **Security** ‚Üí **Modify IAM role**
4. W√§hle: `EC2-S3-Access-Role`
5. **Update IAM role**

**Wichtig:** Es kann 1-2 Minuten dauern bis die Rolle aktiv wird!

**Auf dem Server testen (SSH):**

```bash
# Teste ob AWS CLI funktioniert
aws --version
# Sollte Version anzeigen

# Teste ob IAM-Rolle greift
aws sts get-caller-identity

# Sollte zeigen:
# {
#     "UserId": "AROAXXXXXXXXX:i-xxxxxxxxx",
#     "Account": "123456789012",
#     "Arn": "arn:aws:sts::123456789012:assumed-role/EC2-S3-Access-Role/i-xxxxx"
# }

# Wenn Fehler "Unable to locate credentials":
# ‚Üí IAM-Rolle ist noch nicht aktiv, warte 1-2 Minuten

# Teste S3-Zugriff
aws s3 ls
# Sollte deine Buckets auflisten
```

### Schritt 3: Logging in der Anwendung aktivieren

**Auf dem Server:**

```bash
cd ~/notes-api
```

**Erstelle eine neue Datei `logger_config.py`:**

```bash
nano logger_config.py
```

**F√ºge ein:**

```python
"""
Logging-Konfiguration f√ºr Notes API
"""
import logging
from logging.handlers import RotatingFileHandler
import os

# Log-Verzeichnis erstellen
LOG_DIR = "/var/log/notes-api"
os.makedirs(LOG_DIR, exist_ok=True)

def setup_logger():
    """
    Richtet den Logger ein mit File Handler und Rotation.
    
    Returns:
        logging.Logger: Konfigurierter Logger
    """
    logger = logging.getLogger("notes-api")
    logger.setLevel(logging.INFO)
    
    # Verhindere Handler-Duplikate (wichtig bei mehrfachem Aufruf)
    if logger.handlers:
        return logger
    
    # Format f√ºr Log-Nachrichten
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    
    # File Handler mit Rotation
    # Wenn Datei 10MB erreicht, neue Datei erstellen
    # Behalte max. 5 Backup-Dateien
    file_handler = RotatingFileHandler(
        f"{LOG_DIR}/api.log",
        maxBytes=10*1024*1024,  # 10 MB
        backupCount=5
    )
    file_handler.setFormatter(formatter)
    logger.addHandler(file_handler)
    
    # Console Handler (zus√§tzlich)
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)
    
    return logger
```

**Speichern:** Strg+X, Y, Enter

### Schritt 4: Logger in main.py einbinden

**Bearbeite `main.py`:**

```bash
nano main.py
```

**Am Anfang hinzuf√ºgen (nach den anderen Imports):**

```python
from logger_config import setup_logger

# Logger initialisieren
logger = setup_logger()
```

**In den Endpoints Logging hinzuf√ºgen:**

```python
@app.get("/notes")
def get_notes(
    limit: int = Query(100, ge=1, le=100),
    search: Optional[str] = Query(None, min_length=2)
):
    """Alle Notizen abrufen mit Logging."""
    logger.info(f"GET /notes - limit={limit}, search={'***' if search else 'None'}")
    notes = db.get_all_notes(limit=limit, search=search)
    logger.info(f"Returning {len(notes)} notes")
    return notes

@app.post("/notes", status_code=201)
def create_note(note: NoteCreate):
    """Neue Notiz erstellen mit Logging."""
    logger.info(f"POST /notes - Creating note (len={len(note.text)})")
    new_id = db.create_note(note.text)
    
    if new_id is None:
        logger.error("Failed to create note")
        raise HTTPException(500, "Fehler beim Erstellen der Notiz")
    
    logger.info(f"Created note with ID: {new_id}")
    return {"id": new_id, "text": note.text}

# F√ºge Logging zu allen anderen Endpoints hinzu...
```

**Wichtig zum Logging:**
* Logge **L√§nge** statt Inhalt (`len={len(note.text)}`) ‚Üí Datenschutz!
* Maskiere Suchbegriffe (`'***' if search else 'None'`) ‚Üí Keine sensiblen Daten im Log
* Logge IDs, Counts, Status ‚Üí Gut f√ºr Debugging ohne Privacy-Risiko

**Speichern:** Strg+X, Y, Enter

### Schritt 5: Log-Verzeichnis vorbereiten (WICHTIG - vor Service-Start!)

```bash
# Log-Verzeichnis erstellen
sudo mkdir -p /var/log/notes-api

# Besitzer auf ubuntu setzen
sudo chown ubuntu:ubuntu /var/log/notes-api

# Berechtigungen setzen
sudo chmod 755 /var/log/notes-api

# √úberpr√ºfen
ls -ld /var/log/notes-api
# Sollte zeigen: drwxr-xr-x ... ubuntu ubuntu ... /var/log/notes-api
```

**Warum JETZT?**
* RotatingFileHandler braucht Schreibrechte auf das Verzeichnis
* Wenn das Verzeichnis nicht existiert oder falsche Rechte hat ‚Üí Service startet nicht
* Besser jetzt vorbereiten, bevor wir den Service starten!

### Schritt 6: Service neu starten

```bash
# Service neu starten (neue Logging-Konfiguration laden)
sudo systemctl restart notes-api

# Status √ºberpr√ºfen
sudo systemctl status notes-api

# Logs ansehen
sudo tail -f /var/log/notes-api/api.log
```

**Teste die API:**
```bash
# Erstelle ein paar Requests
curl http://localhost:8000/notes
curl -X POST http://localhost:8000/notes \
  -H "Content-Type: application/json" \
  -d '{"text": "Test Notiz"}'
```

**Logs sollten jetzt erscheinen!**

### Schritt 7: S3-Upload-Script erstellen

**Erstelle ein Script f√ºr S3-Upload:**

```bash
nano ~/notes-api/upload-logs-to-s3.sh
```

**F√ºge ein (ersetze BUCKET_NAME):**

```bash
#!/bin/bash
# Script zum Hochladen von Logs zu S3

# Konfiguration
LOG_DIR="/var/log/notes-api"
S3_BUCKET="notes-api-logs-js-2025"  # ERSETZE MIT DEINEM BUCKET!
DATE=$(date +%Y-%m-%d)

# Wechsle in Log-Verzeichnis (mit Fehler-Check)
cd "$LOG_DIR" || exit 1

# Pr√ºfe ob Log-Dateien existieren
if ! ls *.log 1> /dev/null 2>&1; then
    echo "Keine Log-Dateien gefunden. √úberspringe Upload."
    exit 0
fi

# Log-Datei komprimieren
tar -czf "api-logs-${DATE}.tar.gz" *.log

# Zu S3 hochladen
aws s3 cp "api-logs-${DATE}.tar.gz" "s3://${S3_BUCKET}/logs/"

# Alte komprimierte Datei l√∂schen
rm "api-logs-${DATE}.tar.gz"

# Optional: Alte Log-Dateien rotieren
find "$LOG_DIR" -name "*.log.*" -mtime +7 -delete

echo "Logs erfolgreich zu S3 hochgeladen: s3://${S3_BUCKET}/logs/api-logs-${DATE}.tar.gz"
```

**Speichern:** Strg+X, Y, Enter

**Script ausf√ºhrbar machen:**

```bash
chmod +x ~/notes-api/upload-logs-to-s3.sh
```

**Testen:**

```bash
# Script manuell ausf√ºhren
~/notes-api/upload-logs-to-s3.sh

# Sollte ausgeben:
# Logs erfolgreich zu S3 hochgeladen...
```

**In S3 √ºberpr√ºfen:**
* Gehe zur AWS Console ‚Üí S3
* √ñffne deinen Bucket
* Im Ordner `logs/` sollte jetzt eine .tar.gz Datei sein!

### Schritt 8: Cronjob f√ºr automatischen Upload

**√ñffne Crontab:**

```bash
crontab -e

# Beim ersten Mal: W√§hle Editor (nano ist einfacher als vim)
# W√§hle: 1 (nano)
```

**F√ºge am Ende hinzu:**

```bash
# Logs t√§glich um 3 Uhr morgens zu S3 hochladen
0 3 * * * /home/ubuntu/notes-api/upload-logs-to-s3.sh >> /var/log/notes-api/s3-upload.log 2>&1
```

**Speichern:** Strg+X, Y, Enter

**Erkl√§rung des Cronjobs:**

```
0 3 * * *  ‚Üí Zeitpunkt
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ Wochentag (0-7, 0 und 7 = Sonntag)
‚îÇ ‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Monat (1-12)
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Tag (1-31)
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Stunde (0-23)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Minute (0-59)

0 3 * * *  = Jeden Tag um 3:00 Uhr morgens
```

**Weitere Beispiele:**
```bash
# Jede Stunde
0 * * * * /pfad/zum/script.sh

# Jeden Montag um 9:00
0 9 * * 1 /pfad/zum/script.sh

# Jeden Monatsersten um Mitternacht
0 0 1 * * /pfad/zum/script.sh
```

**Cronjobs auflisten:**

```bash
crontab -l
```

**Testen (nicht 3 Uhr warten!):**

```bash
# F√ºhre Script direkt aus
~/notes-api/upload-logs-to-s3.sh

# √úberpr√ºfe Upload-Log
cat /var/log/notes-api/s3-upload.log
```

---

## Mini-Aufgabe

**Aufgabe:** Erstelle einen Health-Check-Endpoint, der auch die Anzahl der Logs-Dateien zur√ºckgibt.

**Anforderungen:**
* Endpoint: `GET /health`
* Response soll enthalten:
  * API-Status
  * Anzahl der Notizen
  * Anzahl der Log-Dateien in `/var/log/notes-api/`

<details>
<summary>L√∂sung anzeigen</summary>

**In main.py:**

```python
import os
from datetime import datetime

@app.get("/health")
def health():
    """
    Health-Check mit System-Informationen.
    """
    # Anzahl der Notizen
    notes_count = db.get_notes_count()
    
    # Anzahl der Log-Dateien
    log_dir = "/var/log/notes-api"
    try:
        log_files = [f for f in os.listdir(log_dir) if f.endswith('.log')]
        log_count = len(log_files)
    except Exception:
        log_count = 0
    
    return {
        "status": "ok",
        "notes_count": notes_count,
        "log_files_count": log_count,
        "timestamp": datetime.now().isoformat()
    }
```

**Testen:**
```bash
curl http://localhost:8000/health
```

**Erwartete Antwort:**
```json
{
  "status": "ok",
  "notes_count": 5,
  "log_files_count": 2,
  "timestamp": "2025-01-15T10:30:00"
}
```

</details>

---

## √úbungen f√ºr Tag 4

### √úbung 1: Umgebungsvariablen verwenden

**Problem:** S3-Bucket-Name ist hardcoded im Script.

**Aufgabe:** Verwende Umgebungsvariablen f√ºr:
* S3-Bucket-Name
* AWS-Region
* Log-Retention-Days

<details>
<summary>L√∂sung anzeigen</summary>

**Erstelle `.env` Datei:**

```bash
nano ~/notes-api/.env
```

**Inhalt:**
```bash
S3_BUCKET=notes-api-logs-js-2025
AWS_REGION=eu-central-1
LOG_RETENTION_DAYS=7
```

**In upload-logs-to-s3.sh:**

```bash
#!/bin/bash

# Lade Umgebungsvariablen (absoluter Pfad f√ºr Cron!)
source /home/ubuntu/notes-api/.env

LOG_DIR="/var/log/notes-api"
DATE=$(date +%Y-%m-%d)

cd $LOG_DIR
tar -czf api-logs-${DATE}.tar.gz *.log

# Verwende Variablen
aws s3 cp api-logs-${DATE}.tar.gz s3://${S3_BUCKET}/logs/ --region ${AWS_REGION}

rm api-logs-${DATE}.tar.gz

# Verwende LOG_RETENTION_DAYS
find $LOG_DIR -name "*.log.*" -mtime +${LOG_RETENTION_DAYS} -delete

echo "Logs uploaded to s3://${S3_BUCKET}/logs/"
```

**Wichtig:** 
* Absoluter Pfad `/home/ubuntu/...` statt `~/...`
* In Cronjobs funktioniert `~` oft nicht zuverl√§ssig
* Besser immer volle Pfade in Scripts die per Cron laufen!

**Vorteile:**
* Einfacher zu konfigurieren
* Keine hardcoded Werte
* Wiederverwendbar auf anderen Servern

</details>

---

### √úbung 2: HTTPS mit Let's Encrypt (Bonus)

**Aufgabe:** Aktiviere HTTPS f√ºr deine API mit einem kostenlosen SSL-Zertifikat.

**Voraussetzung:** Du brauchst eine eigene Domain
* Domain kann bei beliebigem Registrar gekauft werden (z.B. Namecheap, GoDaddy, Ionos)
* G√ºnstige Domains oft ab ~1‚Ç¨/Jahr verf√ºgbar
* **Hinweis:** Kostenlose Domain-Anbieter sind oft unzuverl√§ssig - besser kleine Investition
* F√ºr Testzwecke: Manche Anbieter haben Free Trials

<details>
<summary>Hintergrundwissen</summary>

**Warum HTTPS?**
* Verschl√ºsselte Kommunikation
* Browser zeigen "Sicher" an
* SEO-Vorteil
* Vertrauen der Nutzer

**Was ist Let's Encrypt?**
* Kostenlose SSL-Zertifikate
* Automatische Erneuerung
* Von allen Browsern akzeptiert

**Certbot:**
* Tool zum Einrichten von Let's Encrypt
* Automatisiert den gesamten Prozess

</details>

<details>
<summary>L√∂sung anzeigen</summary>

**Schritt 1: Domain einrichten**

1. Registriere/kaufe eine Domain bei einem Registrar deiner Wahl
2. Gehe zum DNS-Management deines Providers
3. Erstelle einen A-Record:
   * Type: A
   * Name: @ (f√ºr root domain) oder api (f√ºr Subdomain)
   * Value: DEINE_EC2_IP
   * TTL: 3600 (oder lasse den Standard)
4. Warte 5-15 Minuten bis DNS propagiert ist

**Schritt 2: Certbot installieren**

```bash
# Snapd installieren (falls nicht vorhanden)
sudo apt install snapd

# Certbot installieren
sudo snap install --classic certbot

# Symlink erstellen
sudo ln -s /snap/bin/certbot /usr/bin/certbot
```

**Schritt 3: Nginx-Konfiguration anpassen**

```bash
sudo nano /etc/nginx/sites-available/notes-api
```

**√Ñndere `server_name`:**
```nginx
server {
    listen 80;
    server_name deine-domain.com;  # ERSETZE MIT DEINER DOMAIN
    # Rest bleibt gleich
}
```

**Schritt 4: Zertifikat erstellen**

```bash
# Certbot mit Nginx-Plugin
sudo certbot --nginx -d deine-domain.com

# Folge den Anweisungen:
# - Email eingeben
# - Bedingungen akzeptieren
# - Redirect auf HTTPS? JA
```

**Certbot macht automatisch:**
* Erstellt SSL-Zertifikat
* Passt Nginx-Konfiguration an
* Erstellt Cronjob f√ºr Auto-Renewal

**Schritt 5: Testen**

```bash
# Im Browser √∂ffnen
https://deine-domain.com
https://deine-domain.com/docs
```

**Du solltest jetzt ein gr√ºnes Schloss sehen!**

**Security Group anpassen:**
* Gehe zu AWS Console ‚Üí EC2 ‚Üí Security Groups
* F√ºge Regel hinzu:
  * Type: HTTPS
  * Port: 443
  * Source: Anywhere (0.0.0.0/0)

</details>

---

### √úbung 3: Monitoring mit simple Health-Check

**Aufgabe:** Implementiere einen einfachen Monitoring-Mechanismus.

<details>
<summary>L√∂sung anzeigen</summary>

**Erstelle ein Monitoring-Script:**

```bash
nano ~/notes-api/health-check.sh
```

**Inhalt:**

```bash
#!/bin/bash
# Einfacher Health-Check

API_URL="http://localhost:8000/health"
LOG_FILE="/var/log/notes-api/health-check.log"

# Aktuelles Datum
DATE=$(date '+%Y-%m-%d %H:%M:%S')

# Health-Check durchf√ºhren
RESPONSE=$(curl -s -o /dev/null -w "%{http_code}" $API_URL)

if [ $RESPONSE -eq 200 ]; then
    echo "$DATE - OK - API is healthy (HTTP $RESPONSE)" >> $LOG_FILE
else
    echo "$DATE - ERROR - API is down (HTTP $RESPONSE)" >> $LOG_FILE
    
    # Optional: Service neu starten
    # sudo systemctl restart notes-api
    
    # Optional: Email senden
    # echo "API is down!" | mail -s "Alert: API Down" deine@email.com
fi
```

**Ausf√ºhrbar machen:**
```bash
chmod +x ~/notes-api/health-check.sh
```

**Cronjob hinzuf√ºgen (alle 5 Minuten):**
```bash
crontab -e
```

**F√ºge hinzu:**
```bash
# Health-Check alle 5 Minuten
*/5 * * * * /home/ubuntu/notes-api/health-check.sh
```

**Logs ansehen:**
```bash
tail -f /var/log/notes-api/health-check.log
```

</details>

---

### √úbung 4 (Bonus): Database Backup zu S3

**Aufgabe:** Erstelle ein Script, das die SQLite-Datenbank t√§glich zu S3 sichert.

<details>
<summary>L√∂sung anzeigen</summary>

**Schritt 1: SQLite CLI installieren (falls nicht vorhanden)**

```bash
# SQLite3 CLI installieren
sudo apt install -y sqlite3

# √úberpr√ºfen
sqlite3 --version
# Sollte Version anzeigen, z.B. 3.37.2
```

**Schritt 2: Backup-Script erstellen**

**Erstelle Backup-Script:**

```bash
nano ~/notes-api/backup-db-to-s3.sh
```

**Inhalt:**

```bash
#!/bin/bash
# Datenbank-Backup zu S3

DB_PATH="/home/ubuntu/notes-api/notes.db"
BACKUP_DIR="/tmp/db-backups"
S3_BUCKET="notes-api-logs-js-2025"  # DEIN BUCKET
DATE=$(date +%Y-%m-%d)

# Backup-Verzeichnis erstellen
mkdir -p $BACKUP_DIR

# SQLite-Datenbank exportieren (sauber)
sqlite3 $DB_PATH ".backup '$BACKUP_DIR/notes-${DATE}.db'"

# Komprimieren
cd $BACKUP_DIR
gzip notes-${DATE}.db

# Zu S3 hochladen
aws s3 cp notes-${DATE}.db.gz s3://${S3_BUCKET}/backups/

# Lokales Backup l√∂schen
rm notes-${DATE}.db.gz

# Alte Backups in S3 l√∂schen (√§lter als 30 Tage)
# aws s3 ls s3://${S3_BUCKET}/backups/ | ... (komplexer)

echo "Backup erfolgreich: s3://${S3_BUCKET}/backups/notes-${DATE}.db.gz"
```

**Ausf√ºhrbar machen:**
```bash
chmod +x ~/notes-api/backup-db-to-s3.sh
```

**Cronjob hinzuf√ºgen (t√§glich um 2 Uhr):**
```bash
crontab -e
```

**F√ºge hinzu:**
```bash
# Database Backup t√§glich um 2:00
0 2 * * * /home/ubuntu/notes-api/backup-db-to-s3.sh >> /var/log/notes-api/backup.log 2>&1
```

**Testen:**
```bash
~/notes-api/backup-db-to-s3.sh

# In S3 √ºberpr√ºfen
aws s3 ls s3://DEIN-BUCKET/backups/
```

</details>

---

## Zusammenfassung Tag 4

**Was haben wir gelernt?**

### Kernziele (Pflicht) 

Diese Ziele machen die API produktiv erreichbar:

**AWS EC2:**
* EC2-Instanz erstellen und konfigurieren
* Security Groups (Firewall) einrichten
* SSH-Verbindung mit Key-Pair
* Public IP und Netzwerk-Grundlagen
* Instanztypen verstehen (t2.micro/t3.micro)

**Server-Setup:**
* Ubuntu-Server aktualisieren
* Python, Nginx, AWS CLI installieren
* Virtual Environment erstellen
* Code auf Server deployen

**Systemd Service:**
* Service-Datei erstellen
* Service aktivieren und starten
* Automatisches Starten beim Boot
* Logs mit journalctl ansehen
* FastAPI auf localhost (127.0.0.1) binden

**Nginx Reverse Proxy:**
* Nginx-Konfiguration schreiben
* Upstream-Block verstehen
* Proxy-Headers setzen
* API √ºber Port 80 erreichbar machen
* Defense in Depth (Nginx als Gateway)

**Ergebnis:** API ist √∂ffentlich √ºber `http://DEINE_IP/docs` erreichbar! üéâ

---

### Bonus-Ziele (Optional) ‚≠ê

Diese erweitern das Setup um Production-Features:

**Logging:**
* Python Logging-Modul nutzen
* RotatingFileHandler f√ºr Log-Rotation
* Logs in Dateien schreiben
* Handler-Duplikate vermeiden

**S3 und Automatisierung:**
* S3-Bucket erstellen
* IAM-Rolle f√ºr EC2 einrichten
* Shell-Script f√ºr S3-Upload
* Cronjobs einrichten
* Automatische Log-Archivierung

**HTTPS (√úbung 2):**
* Domain einrichten
* Let's Encrypt Zertifikat
* HTTPS aktivieren

**Monitoring und Backups (√úbungen 3+4):**
* Health-Check Endpoint
* Database Backups zu S3
* Umgebungsvariablen

---

### Best Practices
* Nicht als root laufen
* Security Groups restriktiv konfigurieren
* Private Keys sicher verwahren
* Logs rotieren und archivieren
* Automatisierung mit Cronjobs

---

## Troubleshooting Guide

### Problem: SSH Connection refused

**Symptom:**
```bash
ssh: connect to host 54.93.123.456 port 22: Connection refused
```

**L√∂sungen:**
1. Ist die Instanz "Running"? (AWS Console √ºberpr√ºfen)
2. Security Group: Port 22 offen f√ºr deine IP?
3. Ist "Auto-assign public IP" aktiviert?
4. Firewall auf deinem Laptop blockiert SSH?

### Problem: API nicht erreichbar

**Symptom:**
```bash
curl http://DEINE_IP
# Connection refused
```

**L√∂sungen:**

1. **Ist der Service running?**
   ```bash
   sudo systemctl status notes-api
   # Sollte "active (running)" zeigen
   ```

2. **L√§uft Nginx?**
   ```bash
   sudo systemctl status nginx
   ```

3. **Security Group: Port 80 offen?**
   * AWS Console ‚Üí EC2 ‚Üí Security Groups
   * Inbound Rules: HTTP (80) auf 0.0.0.0/0?

4. **Nginx-Logs √ºberpr√ºfen:**
   ```bash
   sudo tail -f /var/log/nginx/notes-api-error.log
   ```

5. **API-Logs √ºberpr√ºfen:**
   ```bash
   sudo journalctl -u notes-api -f
   ```

### Problem: S3-Upload schl√§gt fehl

**Symptom:**
```bash
upload failed: Unable to locate credentials
```

**L√∂sungen:**

1. **IAM-Rolle angeh√§ngt?**
   * AWS Console ‚Üí EC2 ‚Üí Instanz ‚Üí Security ‚Üí IAM role
   * Sollte eine Rolle anzeigen

2. **AWS CLI konfiguriert?**
   ```bash
   # Test ob Credentials funktionieren
   aws s3 ls
   ```

3. **Bucket-Name korrekt?**
   ```bash
   # Liste alle Buckets
   aws s3 ls
   ```

### Problem: Cronjob l√§uft nicht

**Symptom:**
```bash
crontab -l
# Cronjob ist da, aber Script l√§uft nicht
```

**L√∂sungen:**

1. **Script ausf√ºhrbar?**
   ```bash
   ls -la ~/notes-api/upload-logs-to-s3.sh
   # Sollte -rwxr-xr-x zeigen (x = executable)
   
   # Falls nicht:
   chmod +x ~/notes-api/upload-logs-to-s3.sh
   ```

2. **Absolute Pfade verwenden:**
   ```bash
   # Im Cronjob immer volle Pfade:
   0 3 * * * /home/ubuntu/notes-api/upload-logs-to-s3.sh
   # NICHT: ~/notes-api/upload-logs-to-s3.sh
   ```

3. **Output umleiten:**
   ```bash
   # F√ºge am Ende hinzu:
   0 3 * * * /home/ubuntu/notes-api/upload-logs-to-s3.sh >> /tmp/cron.log 2>&1
   
   # Dann logs ansehen:
   cat /tmp/cron.log
   ```

4. **Cron-Mail √ºberpr√ºfen:**
   ```bash
   sudo tail /var/mail/ubuntu
   ```

---

## Checkliste Tag 4

### Kernziele (Pflicht) 

**AWS Setup:**
- [ ] AWS Sandbox-Zugang funktioniert (https://sandboxes.techstarter.de/)
- [ ] EC2-Instanz erstellt (t2.micro oder t3.micro, Free tier eligible)
- [ ] Security Group konfiguriert (SSH Port 22 + HTTP Port 80)
- [ ] Private Key (.pem) heruntergeladen und gesichert
- [ ] SSH-Verbindung funktioniert

**Server-Konfiguration:**
- [ ] System aktualisiert (apt update && upgrade)
- [ ] Python, pip, venv installiert
- [ ] Nginx installiert
- [ ] AWS CLI installiert
- [ ] Git installiert (optional)
- [ ] Code auf Server kopiert
- [ ] Virtual Environment erstellt
- [ ] Dependencies installiert (FastAPI, Uvicorn)

**Systemd Service:**
- [ ] Service-Datei erstellt (mit --host 127.0.0.1)
- [ ] Service aktiviert und gestartet
- [ ] Service l√§uft (systemctl status zeigt "active running")
- [ ] Service √ºberlebt Neustart (getestet mit sudo reboot)

**Nginx Reverse Proxy:**
- [ ] Nginx-Konfiguration erstellt
- [ ] Konfiguration aktiviert (Symlink)
- [ ] Nginx-Config getestet (nginx -t)
- [ ] Nginx neu geladen
- [ ] API erreichbar von au√üen: `http://DEINE_IP/docs`
- [ ] Swagger UI funktioniert

** Wenn alle obigen Punkte vorhanden sind: Kernziel erreicht!**

---

### Bonus-Ziele (Optional) ‚≠ê

**Logging (Bonus):**
- [ ] Logger-Konfiguration erstellt (logger_config.py)
- [ ] Log-Verzeichnis vorbereitet (/var/log/notes-api)
- [ ] Handler-Duplikate Check eingebaut
- [ ] Logging in Endpoints eingebaut
- [ ] Logs werden geschrieben und rotiert

**S3 und Backup (Bonus):**
- [ ] S3-Bucket erstellt
- [ ] IAM-Rolle erstellt und an EC2 angeh√§ngt
- [ ] AWS CLI Credentials getestet (aws sts get-caller-identity)
- [ ] Upload-Script erstellt (mit Guard f√ºr fehlende Logs)
- [ ] Upload-Script funktioniert
- [ ] Cronjob eingerichtet
- [ ] Automatischer Upload funktioniert

**√úbungen (Bonus):**
- [ ] Umgebungsvariablen (.env) implementiert
- [ ] HTTPS mit Let's Encrypt (wenn Domain vorhanden)
- [ ] Health-Check Monitoring
- [ ] Database Backup zu S3

---

## Ausblick auf Tag 5

Morgen k√∂nnten wir folgende Themen behandeln:

**M√∂gliche Themen:**
* **CI/CD:** GitHub Actions f√ºr automatisches Deployment
* **Docker:** Anwendung containerisieren
* **Monitoring:** Grafana + Prometheus f√ºr Metriken
* **Testing:** Automatische Tests mit pytest
* **Datenbank:** Migration von SQLite zu PostgreSQL
* **Advanced:** Load Balancing mit mehreren EC2-Instanzen

---

## Kosten-√úbersicht und Aufr√§umen

### Was kostet was?

**F√ºr diesen Kurs (Techstarter Sandbox):**
* Budget-Limit: 15‚Ç¨ pro Teilnehmer
* **Wichtig:** Kosten variieren nach Region, Nutzung und Zeitraum
* Eine kleine Instanz (t2.micro/t3.micro) verbraucht typisch einige Euro pro Woche bei 24/7 Betrieb
* S3 Storage und Transfers sind bei unserem Umfang meist unter 1‚Ç¨
* **Am besten:** Beobachte im Sandbox-Dashboard dein Budget und r√§ume t√§glich auf!
* **WICHTIG:** Am Ende des Tages/Projekts aufr√§umen (siehe unten)!

**Eigene AWS Accounts (Free Tier):**

Die Free Tier Konditionen variieren je nach Account-Erstellungsdatum:

**Legacy Free Tier (Accounts vor Juli 2025):**
* 750 Stunden EC2 t2.micro/Monat (12 Monate)
* 5 GB S3 Storage
* 15 GB Daten√ºbertragung aus EC2

**Aktuelles Free Tier:**
* Konditionen variieren - pr√ºfe im AWS Free Tier Dashboard
* Achte auf "Free tier eligible" Labels
* Oft √§hnliche oder bessere Konditionen

**Nach Free Tier (oder au√üerhalb):**
* t2.micro: ~8-10‚Ç¨/Monat
* t3.micro: ~9-11‚Ç¨/Monat  
* S3 Storage: ~0,023‚Ç¨/GB/Monat
* S3 Requests: Vernachl√§ssigbar f√ºr kleine Projekte

**Kosten sparen:**

**In der Techstarter Sandbox:**
* Instanz **terminate** nach dem Training (nicht stop!)
* Auch gestoppte Instanzen verbrauchen Budget durch EBS Storage
* S3 Buckets komplett leeren und l√∂schen
* Siehe detaillierte Aufr√§um-Anleitung weiter unten

**Eigener AWS Account:**
* Instanz **stoppen** wenn du sp√§ter weitermachen willst (nicht terminate!)
* Bei "Stop" bezahlst du nur EBS Storage (~0,80‚Ç¨/Monat f√ºr 8GB)
* S3-Lifecycle-Policies f√ºr alte Logs einrichten
* Elastic IPs freigeben wenn nicht genutzt

### Ressourcen aufr√§umen (wichtig f√ºr Sandbox!)

**Wenn du in der Techstarter Sandbox arbeitest:**

Am Ende des Trainings/Tages solltest du aufr√§umen, um Budget zu sparen:

1. **EC2-Instanz TERMINATE (l√∂schen):**
   ```bash
   # In AWS Console:
   EC2 ‚Üí Instances ‚Üí Instanz ausw√§hlen ‚Üí Instance State ‚Üí Terminate
   ```
   * **Warum terminate?** Sandbox hat Budget-Limit (15‚Ç¨)
   * Selbst gestoppte Instanzen kosten durch EBS Storage (~0,80‚Ç¨/Monat)
   * **WARNUNG:** Alle Daten sind weg! Vorher wichtige Daten sichern!

2. **S3-Bucket aufr√§umen:**
   ```bash
   # Alle Objekte l√∂schen
   aws s3 rm s3://DEIN-BUCKET --recursive
   
   # Bucket l√∂schen
   aws s3 rb s3://DEIN-BUCKET
   ```
   * S3 Storage kostet auch wenn wenig - besser komplett leeren

3. **Elastic IPs freigeben** (falls du eine reserviert hast):
   * EC2 ‚Üí Elastic IPs ‚Üí Adresse ausw√§hlen ‚Üí Release
   * Ungenutzte Elastic IPs kosten Geld!

4. **Security Group l√∂schen** (optional, falls selbst erstellt):
   * EC2 ‚Üí Security Groups ‚Üí `notes-api-sg` ausw√§hlen ‚Üí Delete
   * Nur m√∂glich wenn keine Instanz mehr damit verbunden ist

5. **IAM Role aufr√§umen** (optional):
   * IAM ‚Üí Roles ‚Üí `EC2-S3-Access-Role` ‚Üí Delete
   * Vorsicht: Nur l√∂schen wenn du sie selbst erstellt hast!
   * Manche Sandboxes erlauben das L√∂schen von Roles nicht

6. **Key Pair l√∂schen** (optional):
   * EC2 ‚Üí Key Pairs ‚Üí `notes-api-key` ausw√§hlen ‚Üí Delete
   * Nur die AWS-seitige Registrierung, deine lokale .pem-Datei bleibt

**Minimale Aufr√§um-Checkliste f√ºr Sandbox:**
-  EC2-Instanz terminieren
-  S3-Bucket leeren und l√∂schen
-  Elastic IPs freigeben (falls vorhanden)
-  Security Group l√∂schen (wenn m√∂glich)
-  IAM Role l√∂schen (wenn selbst erstellt und erlaubt)

**Wenn du in deinem eigenen AWS Account arbeitest:**

Hier kannst du die Instanz stoppen statt l√∂schen, wenn du sp√§ter weitermachen willst:

1. **EC2-Instanz STOPPEN (nicht l√∂schen!):**
   ```bash
   # In AWS Console:
   EC2 ‚Üí Instances ‚Üí Instanz ausw√§hlen ‚Üí Instance State ‚Üí Stop
   ```
   * Bei "Stop" bleiben alle Daten erhalten
   * Du zahlst nur f√ºr EBS Storage (~0,80‚Ç¨/Monat f√ºr 8GB)
   * Kannst sie jederzeit wieder starten
   * Public IP √§ndert sich beim Neustart (au√üer du nutzt Elastic IP)

2. **EC2-Instanz L√ñSCHEN (nur wenn sicher!):**
   ```bash
   # In AWS Console:
   EC2 ‚Üí Instances ‚Üí Instanz ausw√§hlen ‚Üí Instance State ‚Üí Terminate
   ```
   * **WARNUNG:** Alle Daten sind weg!
   * Kann nicht r√ºckg√§ngig gemacht werden!
   * Nur wenn du das Projekt nicht mehr brauchst

3. **S3-Bucket aufr√§umen:**
   ```bash
   # Alle Objekte l√∂schen
   aws s3 rm s3://DEIN-BUCKET --recursive
   
   # Bucket l√∂schen
   aws s3 rb s3://DEIN-BUCKET
   ```

**Zusammenfassung:**
* **Sandbox:** Terminate + S3 l√∂schen (Budget schonen)
* **Eigener Account:** Stop (weitermachen) oder Terminate (beenden)

---

## Finale Projekt-Struktur

**Auf dem Server:**

```
/home/ubuntu/notes-api/
‚îú‚îÄ‚îÄ venv/                      # Virtual Environment
‚îú‚îÄ‚îÄ main.py                    # FastAPI Anwendung
‚îú‚îÄ‚îÄ db.py                      # Datenbank-Modul
‚îú‚îÄ‚îÄ logger_config.py           # Logging-Konfiguration
‚îú‚îÄ‚îÄ notes.db                   # SQLite-Datenbank
‚îú‚îÄ‚îÄ upload-logs-to-s3.sh       # S3-Upload-Script
‚îú‚îÄ‚îÄ backup-db-to-s3.sh         # Backup-Script (Bonus)
‚îî‚îÄ‚îÄ health-check.sh            # Monitoring-Script (Bonus)

/etc/systemd/system/
‚îî‚îÄ‚îÄ notes-api.service          # Systemd Service

/etc/nginx/sites-available/
‚îî‚îÄ‚îÄ notes-api                  # Nginx-Konfiguration

/var/log/notes-api/
‚îú‚îÄ‚îÄ api.log                    # Anwendungs-Logs
‚îú‚îÄ‚îÄ api.log.1                  # Rotierte Logs
‚îú‚îÄ‚îÄ s3-upload.log              # S3-Upload-Logs
‚îî‚îÄ‚îÄ health-check.log           # Health-Check-Logs
```

**In AWS:**

```
EC2:
‚îî‚îÄ‚îÄ notes-api-server (t2.micro)
    ‚îú‚îÄ‚îÄ Security Group (SSH + HTTP)
    ‚îî‚îÄ‚îÄ IAM Role (S3 Access)

S3:
‚îî‚îÄ‚îÄ notes-api-logs-XXXX/
    ‚îú‚îÄ‚îÄ logs/
    ‚îÇ   ‚îú‚îÄ‚îÄ api-logs-2025-01-15.tar.gz
    ‚îÇ   ‚îî‚îÄ‚îÄ api-logs-2025-01-16.tar.gz
    ‚îî‚îÄ‚îÄ backups/ (optional)
        ‚îú‚îÄ‚îÄ notes-2025-01-15.db.gz
        ‚îî‚îÄ‚îÄ notes-2025-01-16.db.gz
```

---

## Best Practices Zusammenfassung

**Sicherheit:**
* Nie als root arbeiten
* Private Keys mit chmod 400
* Security Groups restriktiv
* Regelm√§√üige Updates (apt upgrade)
* IAM-Rollen statt Access Keys

**Monitoring:**
* Logs strukturiert schreiben
* Health-Check-Endpoint
* Automatisches Monitoring
* Alerts bei Problemen

**Automatisierung:**
* Cronjobs f√ºr wiederkehrende Aufgaben
* Automatische Backups
* Log-Rotation
* S3-Archivierung

**Deployment:**
* Systemd f√ºr Services
* Nginx als Reverse Proxy
* Nie direkt auf Port 8000 exponieren
* Virtual Environment nutzen

**Dokumentation:**
* Alle Scripts dokumentieren
* Konfigurationen kommentieren
* README.md erstellen
* Deployment-Schritte festhalten

---

** Gl√ºckwunsch! Du hast eine vollst√§ndige Production-Umgebung aufgesetzt!**

**Deine API ist jetzt:**
*  √ñffentlich erreichbar
*  Automatisch startend
*  Professionell geloggt
*  Automatisch gesichert
*  Produktionsreif!

**Bei Fragen meldet euch bei Patrick oder mir. Viel Erfolg!**
